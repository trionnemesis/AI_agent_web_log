# Logstash Pipeline 配置
# 用於接收並處理來自 Wazuh、Filebeat 和其他來源的日誌

input {
  # Filebeat 輸入
  beats {
    port => 5044
    type => "filebeat"
  }
  
  # HTTP 輸入（用於接收 JSON 格式的日誌）
  http {
    port => 8080
    codec => "json"
    type => "http"
  }
  
  # Syslog 輸入
  syslog {
    port => 5514
    type => "syslog"
  }
  
  # 檔案輸入（監控特定目錄）
  file {
    path => "/var/log/wazuh/alerts/*.json"
    start_position => "beginning"
    codec => "json"
    type => "wazuh"
  }
}

filter {
  # 時間戳處理
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss" ]
      target => "@timestamp"
    }
  } else {
    mutate {
      add_field => { "timestamp" => "%{@timestamp}" }
    }
  }
  
  # Wazuh 日誌處理
  if [type] == "wazuh" {
    mutate {
      add_field => { 
        "log_source" => "wazuh"
        "alert_id" => "%{[data][id]}"
        "wazuh_rule_id" => "%{[rule][id]}"
      }
      rename => { "[data][full_log]" => "raw_log" }
    }
  }
  
  # Filebeat 日誌處理
  if [type] == "filebeat" {
    mutate {
      add_field => { 
        "log_source" => "%{[fields][service]}"
      }
      rename => { "message" => "raw_log" }
    }
  }
  
  # IP 地址提取
  grok {
    match => { 
      "raw_log" => "%{IP:source_ip}.*%{IP:destination_ip}" 
    }
    tag_on_failure => []
  }
  
  # 日誌級別提取
  if [raw_log] =~ /ERROR|CRITICAL|ALERT/ {
    mutate {
      add_field => { "log_level" => "error" }
    }
  } else if [raw_log] =~ /WARN|WARNING/ {
    mutate {
      add_field => { "log_level" => "warning" }
    }
  } else {
    mutate {
      add_field => { "log_level" => "info" }
    }
  }
  
  # 標記為未分析
  mutate {
    add_field => { "analyzed" => false }
  }
}

output {
  # 輸出到 OpenSearch
  opensearch {
    hosts => ["opensearch:9200"]
    index => "logs-alerts"
    user => "admin"
    password => "admin"
    ssl => false
    ssl_certificate_verification => false
  }
  
  # 調試輸出（可選）
  # stdout {
  #   codec => rubydebug
  # }
} 